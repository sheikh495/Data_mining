{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGCGKU5e4ugGCMoLdwuCOC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sheikh495/Data_mining/blob/main/code_M7__data_mine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.2-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "II3JLM4gHY-C",
        "outputId": "a51a07a1-af84-4b7a-d992-f8092cfd856b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.39)] [\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "\r                                                                               \rGet:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\r0% [2 InRelease 12.7 kB/119 kB 11%] [Connecting to security.ubuntu.com (185.125\r0% [2 InRelease 15.6 kB/119 kB 13%] [Connecting to security.ubuntu.com (185.125\r0% [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadconte\r                                                                               \rGet:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [108 kB]\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,085 kB]\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [419 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [863 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,219 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [960 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [799 kB]\n",
            "Hit:16 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 5,687 kB in 1s (3,961 kB/s)\n",
            "Reading package lists... Done\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "(Reading database ... 120493 files and directories currently installed.)\n",
            "Preparing to unpack .../libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u372-ga~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u372-ga~us1-0ubuntu1~22.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u372-ga~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u372-ga~us1-0ubuntu1~22.04) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u372-ga~us1-0ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u372-ga~us1-0ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
            "tar: spark-3.1.2-bin-hadoop3.2.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall findspark\n",
        "!pip install findspark\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgGnska9HeX2",
        "outputId": "e7873f29-6376-4f53-b2aa-f676dc70b82e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: findspark 2.0.1\n",
            "Uninstalling findspark-2.0.1:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.10/dist-packages/findspark-2.0.1.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/findspark.py\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled findspark-2.0.1\n",
            "Collecting findspark\n",
            "  Using cached findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://downloads.apache.org/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n"
      ],
      "metadata": {
        "id": "JevlsXMMHhkw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark==3.1.1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyFP1zUKHlNz",
        "outputId": "f25d2152-271a-4169-b3cb-cbe7e0c2f9ef"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark==3.1.1\n",
            "  Downloading pyspark-3.1.1.tar.gz (212.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.3/212.3 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9 (from pyspark==3.1.1)\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.6/198.6 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767587 sha256=d217f5abcc0d0e294ff8bfde362c4150afd2e05c48bec0554e1ef421fa46cfec\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/3f/72/8efd988f9ae041f051c75e6834cd92dd6d13a726e206e8b6f3\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.7\n",
            "    Uninstalling py4j-0.10.9.7:\n",
            "      Successfully uninstalled py4j-0.10.9.7\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n"
      ],
      "metadata": {
        "id": "aqqE0xHSHs0h"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/adult.csv', 'r') as file:\n",
        "    header = file.readline()\n",
        "\n",
        "print(header)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJC5jZyxHwkd",
        "outputId": "09cbc34e-36ae-4d1c-fb8b-59e2d173edc6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "age,workclass,fnlwgt,education,educational-num,marital-status,occupation,relationship,race,gender,capital-gain,capital-loss,hours-per-week,native-country,income\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/adult.csv')\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqIqKPzmH0ZY",
        "outputId": "e3482592-f28b-4c8e-870b-4648c0e710f8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       age     workclass  fnlwgt     education  educational-num  \\\n",
            "0       25       Private  226802          11th                7   \n",
            "1       38       Private   89814       HS-grad                9   \n",
            "2       28     Local-gov  336951    Assoc-acdm               12   \n",
            "3       44       Private  160323  Some-college               10   \n",
            "4       18             ?  103497  Some-college               10   \n",
            "...    ...           ...     ...           ...              ...   \n",
            "48837   27       Private  257302    Assoc-acdm               12   \n",
            "48838   40       Private  154374       HS-grad                9   \n",
            "48839   58       Private  151910       HS-grad                9   \n",
            "48840   22       Private  201490       HS-grad                9   \n",
            "48841   52  Self-emp-inc  287927       HS-grad                9   \n",
            "\n",
            "           marital-status         occupation relationship   race  gender  \\\n",
            "0           Never-married  Machine-op-inspct    Own-child  Black    Male   \n",
            "1      Married-civ-spouse    Farming-fishing      Husband  White    Male   \n",
            "2      Married-civ-spouse    Protective-serv      Husband  White    Male   \n",
            "3      Married-civ-spouse  Machine-op-inspct      Husband  Black    Male   \n",
            "4           Never-married                  ?    Own-child  White  Female   \n",
            "...                   ...                ...          ...    ...     ...   \n",
            "48837  Married-civ-spouse       Tech-support         Wife  White  Female   \n",
            "48838  Married-civ-spouse  Machine-op-inspct      Husband  White    Male   \n",
            "48839             Widowed       Adm-clerical    Unmarried  White  Female   \n",
            "48840       Never-married       Adm-clerical    Own-child  White    Male   \n",
            "48841  Married-civ-spouse    Exec-managerial         Wife  White  Female   \n",
            "\n",
            "       capital-gain  capital-loss  hours-per-week native-country income  \n",
            "0                 0             0              40  United-States  <=50K  \n",
            "1                 0             0              50  United-States  <=50K  \n",
            "2                 0             0              40  United-States   >50K  \n",
            "3              7688             0              40  United-States   >50K  \n",
            "4                 0             0              30  United-States  <=50K  \n",
            "...             ...           ...             ...            ...    ...  \n",
            "48837             0             0              38  United-States  <=50K  \n",
            "48838             0             0              40  United-States   >50K  \n",
            "48839             0             0              40  United-States  <=50K  \n",
            "48840             0             0              20  United-States  <=50K  \n",
            "48841         15024             0              40  United-States   >50K  \n",
            "\n",
            "[48842 rows x 15 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq\n"
      ],
      "metadata": {
        "id": "nOcGwDsTH4WC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://downloads.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.2-bin-hadoop3.2.tgz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dScXLz0uH-_X",
        "outputId": "b07d5b11-a83b-4044-dad2-972a21d5a54f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar: spark-3.1.2-bin-hadoop3.2.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark==3.1.2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHXekxwCICU6",
        "outputId": "1b74a310-969e-4807-9118-fc65de41b851"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark==3.1.2\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.4/212.4 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.10/dist-packages (from pyspark==3.1.2) (0.10.9)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880752 sha256=eddde0bf56b905049c4eaf46a741ee4e334c4988caa559011c40d24a93aa9c90\n",
            "  Stored in directory: /root/.cache/pip/wheels/ef/70/50/7882e1bcb5693225f7cc86698f10953201b48b3f36317c2d18\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "  Attempting uninstall: pyspark\n",
            "    Found existing installation: pyspark 3.1.1\n",
            "    Uninstalling pyspark-3.1.1:\n",
            "      Successfully uninstalled pyspark-3.1.1\n",
            "Successfully installed pyspark-3.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install findspark\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_rBdJvRIFfa",
        "outputId": "e6c3d049-952a-4212-990e-0e9063887576"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: findspark in /usr/local/lib/python3.10/dist-packages (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "v09NhJmJIKzu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "7KIlie0CINQM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4S8wDTaIQDB",
        "outputId": "50fc0ff6-4f3e-494d-8c34-819d42510684"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adult.csv    spark-3.1.1-bin-hadoop3.2\n",
            "sample_data  spark-3.1.1-bin-hadoop3.2.tgz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Property used to format output tables better\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "CdfrQtySIQ3n",
        "outputId": "6553e438-f445-4edd-817d-9d867877e72d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7ecc662e3730>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://47d74818f312:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!spark-submit --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9XbYKCKIXZG",
        "outputId": "e34bad5f-d08c-45d9-85f1-86820f50aeaa"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to\n",
            "      ____              __\n",
            "     / __/__  ___ _____/ /__\n",
            "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
            "   /___/ .__/\\_,_/_/ /_/\\_\\   version 3.1.1\n",
            "      /_/\n",
            "                        \n",
            "Using Scala version 2.12.10, OpenJDK 64-Bit Server VM, 1.8.0_362\n",
            "Branch HEAD\n",
            "Compiled by user ubuntu on 2021-02-22T01:33:19Z\n",
            "Revision 1d550c4e90275ab418b9161925049239227f3dc9\n",
            "Url https://github.com/apache/spark\n",
            "Type --help for more information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import necessary libraries\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Step 2: Create a SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"ReadData\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Step 3: Read data from the CSV file\n",
        "data = spark.read \\\n",
        "    .format(\"csv\") \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .load(\"/content/adult.csv\")\n",
        "\n",
        "# Step 4: Show the first few rows of the DataFrame to verify the data\n",
        "data.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_zud6HL2k_o",
        "outputId": "a3eeb9d9-de6c-415d-fcc1-31374535ce04"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------------+------+------------+---------------+------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
            "|age|       workclass|fnlwgt|   education|educational-num|    marital-status|       occupation| relationship|              race|gender|capital-gain|capital-loss|hours-per-week|native-country|income|\n",
            "+---+----------------+------+------------+---------------+------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
            "| 25|         Private|226802|        11th|              7|     Never-married|Machine-op-inspct|    Own-child|             Black|  Male|           0|           0|            40| United-States| <=50K|\n",
            "| 38|         Private| 89814|     HS-grad|              9|Married-civ-spouse|  Farming-fishing|      Husband|             White|  Male|           0|           0|            50| United-States| <=50K|\n",
            "| 28|       Local-gov|336951|  Assoc-acdm|             12|Married-civ-spouse|  Protective-serv|      Husband|             White|  Male|           0|           0|            40| United-States|  >50K|\n",
            "| 44|         Private|160323|Some-college|             10|Married-civ-spouse|Machine-op-inspct|      Husband|             Black|  Male|        7688|           0|            40| United-States|  >50K|\n",
            "| 18|               ?|103497|Some-college|             10|     Never-married|                ?|    Own-child|             White|Female|           0|           0|            30| United-States| <=50K|\n",
            "| 34|         Private|198693|        10th|              6|     Never-married|    Other-service|Not-in-family|             White|  Male|           0|           0|            30| United-States| <=50K|\n",
            "| 29|               ?|227026|     HS-grad|              9|     Never-married|                ?|    Unmarried|             Black|  Male|           0|           0|            40| United-States| <=50K|\n",
            "| 63|Self-emp-not-inc|104626| Prof-school|             15|Married-civ-spouse|   Prof-specialty|      Husband|             White|  Male|        3103|           0|            32| United-States|  >50K|\n",
            "| 24|         Private|369667|Some-college|             10|     Never-married|    Other-service|    Unmarried|             White|Female|           0|           0|            40| United-States| <=50K|\n",
            "| 55|         Private|104996|     7th-8th|              4|Married-civ-spouse|     Craft-repair|      Husband|             White|  Male|           0|           0|            10| United-States| <=50K|\n",
            "| 65|         Private|184454|     HS-grad|              9|Married-civ-spouse|Machine-op-inspct|      Husband|             White|  Male|        6418|           0|            40| United-States|  >50K|\n",
            "| 36|     Federal-gov|212465|   Bachelors|             13|Married-civ-spouse|     Adm-clerical|      Husband|             White|  Male|           0|           0|            40| United-States| <=50K|\n",
            "| 26|         Private| 82091|     HS-grad|              9|     Never-married|     Adm-clerical|Not-in-family|             White|Female|           0|           0|            39| United-States| <=50K|\n",
            "| 58|               ?|299831|     HS-grad|              9|Married-civ-spouse|                ?|      Husband|             White|  Male|           0|           0|            35| United-States| <=50K|\n",
            "| 48|         Private|279724|     HS-grad|              9|Married-civ-spouse|Machine-op-inspct|      Husband|             White|  Male|        3103|           0|            48| United-States|  >50K|\n",
            "| 43|         Private|346189|     Masters|             14|Married-civ-spouse|  Exec-managerial|      Husband|             White|  Male|           0|           0|            50| United-States|  >50K|\n",
            "| 20|       State-gov|444554|Some-college|             10|     Never-married|    Other-service|    Own-child|             White|  Male|           0|           0|            25| United-States| <=50K|\n",
            "| 43|         Private|128354|     HS-grad|              9|Married-civ-spouse|     Adm-clerical|         Wife|             White|Female|           0|           0|            30| United-States| <=50K|\n",
            "| 37|         Private| 60548|     HS-grad|              9|           Widowed|Machine-op-inspct|    Unmarried|             White|Female|           0|           0|            20| United-States| <=50K|\n",
            "| 40|         Private| 85019|   Doctorate|             16|Married-civ-spouse|   Prof-specialty|      Husband|Asian-Pac-Islander|  Male|           0|           0|            45|             ?|  >50K|\n",
            "+---+----------------+------+------------+---------------+------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVeR1JmLsB_Q",
        "outputId": "037ae05e-5e30-41d2-ee95-1a073bf94171"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8033575596273927\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the train data into a DataFrame\n",
        "train_data = pd.read_csv(\"/content/adult.csv\")\n",
        "\n",
        "# Update column names\n",
        "new_column_names = [\n",
        "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"educational-num\",\n",
        "    \"marital-status\", \"occupation\", \"relationship\", \"race\", \"gender\",\n",
        "    \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"\n",
        "]\n",
        "train_data.columns = new_column_names\n",
        "\n",
        "# Separate numerical and categorical features\n",
        "categorical_features = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']\n",
        "numerical_features = ['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
        "\n",
        "# One-hot encode the categorical features\n",
        "ct = ColumnTransformer(\n",
        "    transformers=[('encoder', OneHotEncoder(), categorical_features)],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "X_train_encoded = ct.fit_transform(train_data[new_column_names[:-1]])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train_encoded, train_data[\"income\"], test_size=0.2, random_state=42)\n",
        "\n",
        "# Create an SVM classifier\n",
        "svm = SVC()\n",
        "\n",
        "# Fit the SVM model on the training data\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the trained SVM model on the test set\n",
        "test_predictions = svm.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model on the test set\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, trim\n",
        "from pyspark.ml.classification import RandomForestClassifier, LinearSVC\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "\n",
        "# Load the data into a DataFrame\n",
        "data = spark.read.csv('/content/adult.csv', header=True, inferSchema=True)\n",
        "\n",
        "# Step 2: Drop rows with missing values in any of the selected columns\n",
        "selected_columns = ['age', 'workclass', 'fnlwgt', 'education', 'educational-num', 'marital-status', 'occupation',\n",
        "                    'relationship', 'race', 'gender', 'capital-gain', 'capital-loss', 'hours-per-week',\n",
        "                    'native-country', 'income']\n",
        "data = data.select(selected_columns).na.drop()\n",
        "\n",
        "# Check unique values in the 'income' column\n",
        "data.groupBy('income').count().show()\n",
        "\n",
        "# Clean the 'income' column by removing leading/trailing whitespaces\n",
        "data = data.withColumn('income', trim(col('income')))\n",
        "\n",
        "# Step 3: Encode categorical columns with StringIndexer\n",
        "categorical_columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender']\n",
        "indexers = [StringIndexer(inputCol=column, outputCol=column + \"_index\", handleInvalid='keep').fit(data) for column in categorical_columns]\n",
        "for indexer in indexers:\n",
        "    data = indexer.transform(data)\n",
        "\n",
        "# Step 4: Convert 'income' column to integer type (0 for '<=50K', 1 for '>50K')\n",
        "data = data.withColumn('label', (col('income') == '>50K').cast('int'))\n",
        "\n",
        "# Step 5: Prepare the feature vector\n",
        "feature_columns = ['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss', 'hours-per-week'] + [column + \"_index\" for column in categorical_columns]\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "data = assembler.transform(data)\n",
        "\n",
        "# Split the data into training and testing sets (70% training, 30% testing)\n",
        "train_data, test_data = data.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "# Train the Random Forest model\n",
        "random_forest = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
        "random_forest_model = random_forest.fit(train_data)\n",
        "\n",
        "# Step 6: Evaluate the Random Forest model on the test data\n",
        "rf_predictions = random_forest_model.transform(test_data)\n",
        "rf_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
        "rf_accuracy = rf_evaluator.evaluate(rf_predictions)\n",
        "\n",
        "# Print the evaluation result\n",
        "print(\"Random Forest Model - Accuracy: {:.2f}\".format(rf_accuracy))\n",
        "\n",
        "# Train the Support Vector Machines (SVM) model\n",
        "svm = LinearSVC(featuresCol=\"features\", labelCol=\"label\")\n",
        "svm_model = svm.fit(train_data)\n",
        "\n",
        "# Step 7: Evaluate the SVM model on the test data\n",
        "svm_predictions = svm_model.transform(test_data)\n",
        "svm_accuracy = rf_evaluator.evaluate(svm_predictions)\n",
        "\n",
        "# Print the evaluation result\n",
        "print(\"Support Vector Machines (SVM) Model - Accuracy: {:.2f}\".format(svm_accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwIjTjOd6Dhn",
        "outputId": "356160f7-bb78-40b8-ee17-5286f631a1a0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|income|count|\n",
            "+------+-----+\n",
            "| <=50K|37155|\n",
            "|  >50K|11687|\n",
            "+------+-----+\n",
            "\n",
            "Random Forest Model - Accuracy: 0.84\n",
            "Support Vector Machines (SVM) Model - Accuracy: 0.82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, trim\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "from pyspark.ml.clustering import KMeans\n",
        "\n",
        "# Step 1: Data Preprocessing\n",
        "spark = SparkSession.builder.appName(\"PySpark_Neural_Networks_and_Clustering\").getOrCreate()\n",
        "\n",
        "# Load the data into a DataFrame\n",
        "data = spark.read.csv('/content/adult.csv', header=True, inferSchema=True)\n",
        "\n",
        "# Drop rows with missing values in any of the selected columns\n",
        "selected_columns = ['age', 'workclass', 'fnlwgt', 'education', 'educational-num', 'marital-status', 'occupation',\n",
        "                    'relationship', 'race', 'gender', 'capital-gain', 'capital-loss', 'hours-per-week',\n",
        "                    'native-country', 'income']\n",
        "data = data.select(selected_columns).na.drop()\n",
        "\n",
        "# Clean the 'income' column by removing leading/trailing whitespaces\n",
        "data = data.withColumn('income', trim(col('income')))\n",
        "\n",
        "# Encode categorical columns with StringIndexer\n",
        "categorical_columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']\n",
        "indexers = [StringIndexer(inputCol=column, outputCol=column + \"_index\", handleInvalid='keep').fit(data) for column in categorical_columns]\n",
        "for indexer in indexers:\n",
        "    data = indexer.transform(data)\n",
        "\n",
        "# Convert 'income' column to integer type (0 for '<=50K', 1 for '>50K')\n",
        "data = data.withColumn('label', (col('income') == '>50K').cast('int'))\n",
        "\n",
        "# Step 2: Prepare the feature vector\n",
        "feature_columns = ['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss', 'hours-per-week'] + [column + \"_index\" for column in categorical_columns]\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "data = assembler.transform(data)\n",
        "\n",
        "# Step 3: Split the data into training and testing sets (70% training, 30% testing)\n",
        "train_data, test_data = data.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "# Step 4: Implement Neural Network\n",
        "layers = [len(feature_columns), 5, 4, 2]  # The number of nodes in each layer (input, hidden layers, output)\n",
        "mlp = MultilayerPerceptronClassifier(featuresCol=\"features\", labelCol=\"label\", layers=layers, seed=42)\n",
        "mlp_model = mlp.fit(train_data)\n",
        "\n",
        "# Step 5: Evaluate the Neural Network model on the test data\n",
        "mlp_predictions = mlp_model.transform(test_data)\n",
        "mlp_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
        "mlp_accuracy = mlp_evaluator.evaluate(mlp_predictions)\n",
        "\n",
        "print(\"Neural Network Model - Accuracy: {:.2f}\".format(mlp_accuracy))\n",
        "\n",
        "# Step 6: Implement Unsupervised Learning - K-means Clustering\n",
        "kmeans = KMeans(k=2, seed=42)\n",
        "kmeans_model = kmeans.fit(data)\n",
        "\n",
        "# Step 7: Predict cluster assignments for the data points\n",
        "kmeans_predictions = kmeans_model.transform(data)\n",
        "\n",
        "# Display cluster centers and the number of data points in each cluster\n",
        "kmeans_model.clusterCenters()\n",
        "kmeans_predictions.groupBy(\"prediction\").count().show()\n",
        "\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJIDYfOg8r8g",
        "outputId": "69eb92f8-fa33-448b-983e-bba6c6e188dc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural Network Model - Accuracy: 0.76\n",
            "+----------+-----+\n",
            "|prediction|count|\n",
            "+----------+-----+\n",
            "|         1|12694|\n",
            "|         0|36148|\n",
            "+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"NeuralNetworks\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Step 1: Load the data into a DataFrame\n",
        "data = spark.read.csv('/content/adult.csv', header=True, inferSchema=True)\n",
        "\n",
        "# Step 2: Data Cleaning and Preparation\n",
        "# Drop rows with missing values in any of the selected columns\n",
        "selected_columns = ['age', 'workclass', 'fnlwgt', 'education', 'educational-num', 'marital-status',\n",
        "                    'occupation', 'relationship', 'race', 'gender', 'capital-gain', 'capital-loss',\n",
        "                    'hours-per-week', 'native-country', 'income']\n",
        "data = data.select(selected_columns).na.drop()\n",
        "\n",
        "# Clean the 'income' column by removing leading/trailing whitespaces\n",
        "data = data.withColumn('income', trim(data['income']))\n",
        "\n",
        "# Step 3: Encode categorical columns with StringIndexer\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(data)\n",
        "            for column in ['workclass', 'education', 'marital-status', 'occupation', 'relationship',\n",
        "                           'race', 'gender', 'native-country', 'income']]\n",
        "for indexer in indexers:\n",
        "    data = indexer.transform(data)\n",
        "\n",
        "# Step 4: Prepare the feature vector and rename the 'income' column to 'label'\n",
        "feature_columns = ['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss', 'hours-per-week',\n",
        "                   'workclass_index', 'education_index', 'marital-status_index', 'occupation_index',\n",
        "                   'relationship_index', 'race_index', 'gender_index', 'native-country_index']\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "data = assembler.transform(data).select(\"features\", \"income_index\")\n",
        "\n",
        "# Split the data into training and testing sets (70% training, 30% testing)\n",
        "train_data, test_data = data.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "# Step 5: Implement Neural Network with Cross-Validation\n",
        "layers = [len(feature_columns), 5, 4, 2]  # The number of nodes in each layer (input, hidden layers, output)\n",
        "mlp = MultilayerPerceptronClassifier(featuresCol=\"features\", labelCol=\"income_index\", layers=layers, seed=42)\n",
        "\n",
        "# Create a ParamGrid for hyperparameter tuning\n",
        "paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(mlp.maxIter, [50, 100, 150]) \\\n",
        "    .addGrid(mlp.stepSize, [0.01, 0.05, 0.1]) \\\n",
        "    .build()\n",
        "\n",
        "# Create a CrossValidator to perform cross-validation\n",
        "mlp_evaluator = MulticlassClassificationEvaluator(labelCol=\"income_index\", metricName=\"accuracy\")\n",
        "crossval = CrossValidator(estimator=mlp,\n",
        "                          estimatorParamMaps=paramGrid,\n",
        "                          evaluator=mlp_evaluator,\n",
        "                          numFolds=5,\n",
        "                          seed=42)\n",
        "\n",
        "# Fit the CrossValidator to the training data\n",
        "cv_model = crossval.fit(train_data)\n",
        "\n",
        "# Get the best model from cross-validation\n",
        "best_mlp_model = cv_model.bestModel\n",
        "\n",
        "# Step 6: Evaluate the best Neural Network model on the test data\n",
        "best_mlp_predictions = best_mlp_model.transform(test_data)\n",
        "best_mlp_accuracy = mlp_evaluator.evaluate(best_mlp_predictions)\n",
        "\n",
        "print(\"Best Neural Network Model - Accuracy: {:.2f}\".format(best_mlp_accuracy))\n",
        "\n",
        "# Step 7: Train the model on the entire dataset\n",
        "final_model = mlp.fit(data)\n",
        "\n",
        "# Save the final model\n",
        "final_model.save(\"/content/neural_network_model\")\n",
        "\n",
        "# Stop the SparkSession\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15Sso9F89jV7",
        "outputId": "833cf50b-4cd5-489c-86b5-c0050308e547"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Neural Network Model - Accuracy: 0.77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"AdultCensusPrediction\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Load the data into a DataFrame\n",
        "data = spark.read.csv('/content/adult.csv', header=True, inferSchema=True)\n",
        "\n",
        "# Step 2: Drop rows with missing values in any of the selected columns\n",
        "selected_columns = ['age', 'workclass', 'fnlwgt', 'education', 'educational-num', 'marital-status',\n",
        "                    'occupation', 'relationship', 'race', 'gender', 'capital-gain', 'capital-loss',\n",
        "                    'hours-per-week', 'native-country', 'income']\n",
        "data = data.select(selected_columns).na.drop()\n",
        "\n",
        "# Step 3: Clean the 'income' column by removing leading/trailing whitespaces\n",
        "data = data.withColumn('income', trim(data['income']))\n",
        "\n",
        "# Step 4: Encode categorical columns with StringIndexer\n",
        "categorical_columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']\n",
        "indexers = [StringIndexer(inputCol=column, outputCol=column + \"_index\").fit(data) for column in categorical_columns]\n",
        "for indexer in indexers:\n",
        "    data = indexer.transform(data)\n",
        "\n",
        "# Step 5: Prepare the feature vector and rename the 'income' column to 'label'\n",
        "feature_columns = ['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss', 'hours-per-week'] + [column + \"_index\" for column in categorical_columns]\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "data = assembler.transform(data).select(\"features\", (data[\"income\"] == '>50K').cast('int').alias(\"label\"))\n",
        "\n",
        "# Split the data into training and testing sets (70% training, 30% testing)\n",
        "train_data, test_data = data.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "# Step 6: Implement Neural Network with Cross-Validation\n",
        "layers = [len(feature_columns), 5, 4, 2]  # The number of nodes in each layer (input, hidden layers, output)\n",
        "mlp = MultilayerPerceptronClassifier(featuresCol=\"features\", labelCol=\"label\", layers=layers, seed=42)\n",
        "\n",
        "# Create a ParamGrid for hyperparameter tuning\n",
        "paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(mlp.maxIter, [50, 100, 150]) \\\n",
        "    .addGrid(mlp.stepSize, [0.01, 0.05, 0.1]) \\\n",
        "    .build()\n",
        "\n",
        "# Create a CrossValidator to perform cross-validation\n",
        "mlp_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
        "crossval = CrossValidator(estimator=mlp,\n",
        "                          estimatorParamMaps=paramGrid,\n",
        "                          evaluator=mlp_evaluator,\n",
        "                          numFolds=5,\n",
        "                          seed=42)\n",
        "\n",
        "# Fit the CrossValidator to the training data\n",
        "cv_model = crossval.fit(train_data)\n",
        "\n",
        "# Get the best model from cross-validation\n",
        "best_mlp_model = cv_model.bestModel\n",
        "\n",
        "# Step 7: Evaluate the best Neural Network model on the test data\n",
        "best_mlp_predictions = best_mlp_model.transform(test_data)\n",
        "best_mlp_accuracy = mlp_evaluator.evaluate(best_mlp_predictions)\n",
        "\n",
        "print(\"Best Neural Network Model - Accuracy: {:.2f}\".format(best_mlp_accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNl9cs08-kbY",
        "outputId": "ec0ba5a2-371a-4dc6-c116-2209e3b8aa1e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Neural Network Model - Accuracy: 0.77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"AdultCensusPrediction\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Load the data into a DataFrame\n",
        "data = spark.read.csv('/content/adult.csv', header=True, inferSchema=True)\n",
        "\n",
        "# Step 2: Drop rows with missing values in any of the selected columns\n",
        "selected_columns = ['age', 'workclass', 'fnlwgt', 'education', 'educational-num', 'marital-status',\n",
        "                    'occupation', 'relationship', 'race', 'gender', 'capital-gain', 'capital-loss',\n",
        "                    'hours-per-week', 'native-country', 'income']\n",
        "data = data.select(selected_columns).na.drop()\n",
        "\n",
        "# Step 3: Clean the 'income' column by removing leading/trailing whitespaces\n",
        "data = data.withColumn('income', trim(data['income']))\n",
        "\n",
        "# Step 4: Encode categorical columns with StringIndexer\n",
        "categorical_columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']\n",
        "indexers = [StringIndexer(inputCol=column, outputCol=column + \"_index\").fit(data) for column in categorical_columns]\n",
        "for indexer in indexers:\n",
        "    data = indexer.transform(data)\n",
        "\n",
        "# Step 5: Prepare the feature vector and rename the 'income' column to 'label'\n",
        "feature_columns = ['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss', 'hours-per-week'] + [column + \"_index\" for column in categorical_columns]\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "data = assembler.transform(data).select(\"features\", (data[\"income\"] == '>50K').cast('int').alias(\"label\"))\n",
        "\n",
        "# Split the data into training and testing sets (70% training, 30% testing)\n",
        "train_data, test_data = data.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "# Step 6: Implement Neural Network with Cross-Validation and Hyperparameter Tuning\n",
        "layers = [len(feature_columns), 5, 4, 2]  # The number of nodes in each layer (input, hidden layers, output)\n",
        "mlp = MultilayerPerceptronClassifier(featuresCol=\"features\", labelCol=\"label\", layers=layers, seed=42)\n",
        "\n",
        "# Create a ParamGrid for hyperparameter tuning\n",
        "paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(mlp.maxIter, [100, 150, 200]) \\\n",
        "    .addGrid(mlp.stepSize, [0.01, 0.05, 0.1]) \\\n",
        "    .addGrid(mlp.blockSize, [64, 128]) \\\n",
        "    .build()\n",
        "\n",
        "# Create a CrossValidator to perform cross-validation\n",
        "mlp_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
        "crossval = CrossValidator(estimator=mlp,\n",
        "                          estimatorParamMaps=paramGrid,\n",
        "                          evaluator=mlp_evaluator,\n",
        "                          numFolds=5,\n",
        "                          seed=42)\n",
        "\n",
        "# Fit the CrossValidator to the training data\n",
        "cv_model = crossval.fit(train_data)\n",
        "\n",
        "# Get the best model from cross-validation\n",
        "best_mlp_model = cv_model.bestModel\n",
        "\n",
        "# Step 7: Evaluate the best Neural Network model on the test data\n",
        "best_mlp_predictions = best_mlp_model.transform(test_data)\n",
        "best_mlp_accuracy = mlp_evaluator.evaluate(best_mlp_predictions)\n",
        "\n",
        "print(\"Best Neural Network Model - Accuracy: {:.2f}\".format(best_mlp_accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEXprXSa_NAH",
        "outputId": "0c9cc9af-bfd0-4b04-8712-ff8fc122b16e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Neural Network Model - Accuracy: 0.77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sparklyr\n"
      ],
      "metadata": {
        "id": "oH_kh4kqBFmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"AdultCensusPrediction\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Load the data into a DataFrame\n",
        "data = spark.read.csv('/content/adult.csv', header=True, inferSchema=True)\n",
        "\n",
        "# Step 2: Drop rows with missing values in any of the selected columns\n",
        "selected_columns = ['age', 'workclass', 'fnlwgt', 'education', 'educational-num', 'marital-status',\n",
        "                    'occupation', 'relationship', 'race', 'gender', 'capital-gain', 'capital-loss',\n",
        "                    'hours-per-week', 'native-country', 'income']\n",
        "data = data.select(selected_columns).na.drop()\n",
        "\n",
        "# Step 3: Clean the 'income' column by removing leading/trailing whitespaces\n",
        "data = data.withColumn('income', trim(data['income']))\n",
        "\n",
        "# Step 4: Encode categorical columns with StringIndexer\n",
        "categorical_columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']\n",
        "indexers = [StringIndexer(inputCol=column, outputCol=column + \"_index\").fit(data) for column in categorical_columns]\n",
        "for indexer in indexers:\n",
        "    data = indexer.transform(data)\n",
        "\n",
        "# Step 5: Prepare the feature vector and rename the 'income' column to 'label'\n",
        "feature_columns = ['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss', 'hours-per-week'] + [column + \"_index\" for column in categorical_columns]\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "data = assembler.transform(data).select(\"features\", (data[\"income\"] == '>50K').cast('int').alias(\"label\"))\n",
        "\n",
        "# Split the data into training and testing sets (70% training, 30% testing)\n",
        "train_data, test_data = data.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "# Step 6: Implement Decision Tree Classifier with increased maxBins\n",
        "decision_tree = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\", maxBins=43)\n",
        "\n",
        "# Fit the Decision Tree model on the training data\n",
        "dt_model = decision_tree.fit(train_data)\n",
        "\n",
        "# Step 7: Evaluate the Decision Tree model on the test data\n",
        "dt_predictions = dt_model.transform(test_data)\n",
        "dt_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
        "dt_accuracy = dt_evaluator.evaluate(dt_predictions)\n",
        "\n",
        "print(\"Decision Tree Model - Accuracy: {:.2f}\".format(dt_accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeJNIyirA7Pm",
        "outputId": "a8691e7d-05bf-4eca-ae0d-bfa8221c5efe"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Model - Accuracy: 0.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Create a SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PySpark Classification\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Step 2: Load the data into a DataFrame\n",
        "data = spark.read.csv('/content/adult.csv', header=True, inferSchema=True)\n",
        "\n",
        "# Step 3: Drop rows with missing values in any of the selected columns\n",
        "selected_columns = ['age', 'workclass', 'fnlwgt', 'education', 'educational-num', 'marital-status',\n",
        "                    'occupation', 'relationship', 'race', 'gender', 'capital-gain', 'capital-loss',\n",
        "                    'hours-per-week', 'native-country', 'income']\n",
        "data = data.select(selected_columns).na.drop()\n",
        "\n",
        "# Step 4: Encode categorical columns with StringIndexer\n",
        "categorical_columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']\n",
        "for column in categorical_columns:\n",
        "    indexer = StringIndexer(inputCol=column, outputCol=column + \"_index\")\n",
        "    data = indexer.fit(data).transform(data)\n",
        "\n",
        "# Step 5: Convert the 'income' column to integer type (0 for '<=50K', 1 for '>50K')\n",
        "data = data.withColumn('label', (data['income'] == '>50K').cast('int'))\n",
        "\n",
        "# Step 6: Prepare the feature vector\n",
        "feature_columns = ['age', 'workclass_index', 'fnlwgt', 'education_index', 'educational-num', 'marital-status_index',\n",
        "                   'occupation_index', 'relationship_index', 'race_index', 'gender_index', 'capital-gain',\n",
        "                   'capital-loss', 'hours-per-week', 'native-country_index']\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "data = assembler.transform(data).select(\"features\", \"label\")\n",
        "\n",
        "# Step 7: Split the data into training and testing sets (70% training, 30% testing)\n",
        "train_data, test_data = data.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "# Step 8: Train the Logistic Regression model\n",
        "log_reg = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "log_reg_model = log_reg.fit(train_data)\n",
        "\n",
        "# Step 9: Evaluate the Logistic Regression model on the test data\n",
        "log_reg_predictions = log_reg_model.transform(test_data)\n",
        "log_reg_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
        "log_reg_accuracy = log_reg_evaluator.evaluate(log_reg_predictions)\n",
        "\n",
        "# Step 10: Train the Random Forest model with maxBins=50\n",
        "random_forest = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", maxBins=50)\n",
        "rf_model = random_forest.fit(train_data)\n",
        "\n",
        "# Step 11: Evaluate the Random Forest model on the test data\n",
        "rf_predictions = rf_model.transform(test_data)\n",
        "rf_accuracy = log_reg_evaluator.evaluate(rf_predictions)\n",
        "\n",
        "# Step 12: Print the evaluation results\n",
        "print(\"Logistic Regression Model - Accuracy: {:.2f}\".format(log_reg_accuracy))\n",
        "print(\"Random Forest Model - Accuracy: {:.2f}\".format(rf_accuracy))\n",
        "\n",
        "# Step 13: Create an accuracy diagram\n",
        "accuracy_values = [log_reg_accuracy, rf_accuracy]\n",
        "models = ['Logistic Regression', 'Random Forest']\n",
        "plt.bar(models, accuracy_values)\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Accuracy Comparison')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "_BguMmhbCSUb",
        "outputId": "513edc9c-1f76-42f0-cda7-b55cbb08b919"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Model - Accuracy: 0.84\n",
            "Random Forest Model - Accuracy: 0.85\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Create a SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PySpark Classification\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Step 2: Load the data into a DataFrame\n",
        "data = spark.read.csv('/content/adult.csv', header=True, inferSchema=True)\n",
        "\n",
        "# Step 3: Drop rows with missing values in any of the selected columns\n",
        "selected_columns = ['age', 'workclass', 'fnlwgt', 'education', 'educational-num', 'marital-status',\n",
        "                    'occupation', 'relationship', 'race', 'gender', 'capital-gain', 'capital-loss',\n",
        "                    'hours-per-week', 'native-country', 'income']\n",
        "data = data.select(selected_columns).na.drop()\n",
        "\n",
        "# Step 4: Encode categorical columns with StringIndexer\n",
        "categorical_columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']\n",
        "for column in categorical_columns:\n",
        "    indexer = StringIndexer(inputCol=column, outputCol=column + \"_index\")\n",
        "    data = indexer.fit(data).transform(data)\n",
        "\n",
        "# Step 5: Convert the 'income' column to integer type (0 for '<=50K', 1 for '>50K')\n",
        "data = data.withColumn('label', (data['income'] == '>50K').cast('int'))\n",
        "\n",
        "# Step 6: Prepare the feature vector\n",
        "feature_columns = ['age', 'workclass_index', 'fnlwgt', 'education_index', 'educational-num', 'marital-status_index',\n",
        "                   'occupation_index', 'relationship_index', 'race_index', 'gender_index', 'capital-gain',\n",
        "                   'capital-loss', 'hours-per-week', 'native-country_index']\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "data = assembler.transform(data).select(\"features\", \"label\")\n",
        "\n",
        "# Step 7: Split the data into training and testing sets (70% training, 30% testing)\n",
        "train_data, test_data = data.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "# Step 8: Train the Logistic Regression model\n",
        "log_reg = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "log_reg_model = log_reg.fit(train_data)\n",
        "\n",
        "# Step 9: Evaluate the Logistic Regression model on the test data\n",
        "log_reg_predictions = log_reg_model.transform(test_data)\n",
        "log_reg_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
        "log_reg_accuracy = log_reg_evaluator.evaluate(log_reg_predictions)\n",
        "\n",
        "# Step 10: Train the Random Forest model with maxBins=50\n",
        "random_forest = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", maxBins=50)\n",
        "rf_model = random_forest.fit(train_data)\n",
        "\n",
        "# Step 11: Evaluate the Random Forest model on the test data\n",
        "rf_predictions = rf_model.transform(test_data)\n",
        "\n",
        "# Step 12: Calculate and print evaluation metrics for both models\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "log_reg_accuracy = evaluator.evaluate(log_reg_predictions, {evaluator.metricName: \"accuracy\"})\n",
        "log_reg_precision = evaluator.evaluate(log_reg_predictions, {evaluator.metricName: \"precisionByLabel\"})\n",
        "log_reg_recall = evaluator.evaluate(log_reg_predictions, {evaluator.metricName: \"recallByLabel\"})\n",
        "log_reg_f1 = evaluator.evaluate(log_reg_predictions, {evaluator.metricName: \"f1\"})\n",
        "\n",
        "rf_accuracy = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"accuracy\"})\n",
        "rf_precision = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"precisionByLabel\"})\n",
        "rf_recall = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"recallByLabel\"})\n",
        "rf_f1 = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"f1\"})\n",
        "\n",
        "# Step 13: Print the evaluation results\n",
        "print(\"Logistic Regression Model:\")\n",
        "print(\"Accuracy: {:.2f}\".format(log_reg_accuracy))\n",
        "print(\"Precision: {:.2f}\".format(log_reg_precision))\n",
        "print(\"Recall: {:.2f}\".format(log_reg_recall))\n",
        "print(\"F1 Score: {:.2f}\".format(log_reg_f1))\n",
        "\n",
        "print(\"\\nRandom Forest Model:\")\n",
        "print(\"Accuracy: {:.2f}\".format(rf_accuracy))\n",
        "print(\"Precision: {:.2f}\".format(rf_precision))\n",
        "print(\"Recall: {:.2f}\".format(rf_recall))\n",
        "print(\"F1 Score: {:.2f}\".format(rf_f1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ep1vQ-BEEK_1",
        "outputId": "92683eb5-469a-40a1-b421-fd9137e4c693"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Model:\n",
            "Accuracy: 0.84\n",
            "Precision: 0.86\n",
            "Recall: 0.94\n",
            "F1 Score: 0.83\n",
            "\n",
            "Random Forest Model:\n",
            "Accuracy: 0.85\n",
            "Precision: 0.86\n",
            "Recall: 0.96\n",
            "F1 Score: 0.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "import matplotlib.pyplot as plt\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, NaiveBayes\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "\n",
        "# Step 1: Create a SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PySpark Classification\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Step 2: Load the data into a DataFrame\n",
        "data = spark.read.csv('/content/adult.csv', header=True, inferSchema=True)\n",
        "\n",
        "# Step 3: Drop rows with missing values in any of the selected columns\n",
        "selected_columns = ['age', 'workclass', 'fnlwgt', 'education', 'educational-num', 'marital-status',\n",
        "                    'occupation', 'relationship', 'race', 'gender', 'capital-gain', 'capital-loss',\n",
        "                    'hours-per-week', 'native-country', 'income']\n",
        "data = data.select(selected_columns).na.drop()\n",
        "\n",
        "# Step 4: Encode categorical columns with StringIndexer\n",
        "categorical_columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']\n",
        "for column in categorical_columns:\n",
        "    indexer = StringIndexer(inputCol=column, outputCol=column + \"_index\")\n",
        "    data = indexer.fit(data).transform(data)\n",
        "\n",
        "# Step 5: Convert the 'income' column to integer type (0 for '<=50K', 1 for '>50K')\n",
        "data = data.withColumn('label', (data['income'] == '>50K').cast('int'))\n",
        "\n",
        "# Step 6: Prepare the feature vector\n",
        "feature_columns = ['age', 'workclass_index', 'fnlwgt', 'education_index', 'educational-num', 'marital-status_index',\n",
        "                   'occupation_index', 'relationship_index', 'race_index', 'gender_index', 'capital-gain',\n",
        "                   'capital-loss', 'hours-per-week', 'native-country_index']\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "data = assembler.transform(data).select(\"features\", \"label\")\n",
        "\n",
        "# Step 7: Split the data into training and testing sets (70% training, 30% testing)\n",
        "train_data, test_data = data.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "# Step 8: Train the Logistic Regression model\n",
        "log_reg = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "log_reg_model = log_reg.fit(train_data)\n",
        "\n",
        "# Step 9: Evaluate the Logistic Regression model on the test data\n",
        "log_reg_predictions = log_reg_model.transform(test_data)\n",
        "log_reg_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
        "log_reg_accuracy = log_reg_evaluator.evaluate(log_reg_predictions)\n",
        "\n",
        "# Step 10: Train the Random Forest model with maxBins=50\n",
        "random_forest = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", maxBins=50)\n",
        "rf_model = random_forest.fit(train_data)\n",
        "\n",
        "# Step 11: Train the Naive Bayes model\n",
        "naive_bayes = NaiveBayes(featuresCol=\"features\", labelCol=\"label\")\n",
        "nb_model = naive_bayes.fit(train_data)\n",
        "\n",
        "# Step 12: Evaluate the Random Forest model on the test data\n",
        "rf_predictions = rf_model.transform(test_data)\n",
        "\n",
        "# Step 13: Evaluate the Naive Bayes model on the test data\n",
        "nb_predictions = nb_model.transform(test_data)\n",
        "\n",
        "# Step 14: Calculate and print evaluation metrics for all models\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "log_reg_accuracy = evaluator.evaluate(log_reg_predictions, {evaluator.metricName: \"accuracy\"})\n",
        "log_reg_precision = evaluator.evaluate(log_reg_predictions, {evaluator.metricName: \"precisionByLabel\"})\n",
        "log_reg_recall = evaluator.evaluate(log_reg_predictions, {evaluator.metricName: \"recallByLabel\"})\n",
        "log_reg_f1 = evaluator.evaluate(log_reg_predictions, {evaluator.metricName: \"f1\"})\n",
        "\n",
        "rf_accuracy = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"accuracy\"})\n",
        "rf_precision = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"precisionByLabel\"})\n",
        "rf_recall = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"recallByLabel\"})\n",
        "rf_f1 = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"f1\"})\n",
        "\n",
        "nb_accuracy = evaluator.evaluate(nb_predictions, {evaluator.metricName: \"accuracy\"})\n",
        "nb_precision = evaluator.evaluate(nb_predictions, {evaluator.metricName: \"precisionByLabel\"})\n",
        "nb_recall = evaluator.evaluate(nb_predictions, {evaluator.metricName: \"recallByLabel\"})\n",
        "nb_f1 = evaluator.evaluate(nb_predictions, {evaluator.metricName: \"f1\"})\n",
        "\n",
        "# Step 15: Print the evaluation results for all models\n",
        "print(\"Logistic Regression Model:\")\n",
        "print(\"Accuracy: {:.2f}\".format(log_reg_accuracy))\n",
        "print(\"Precision: {:.2f}\".format(log_reg_precision))\n",
        "print(\"Recall: {:.2f}\".format(log_reg_recall))\n",
        "print(\"F1 Score: {:.2f}\".format(log_reg_f1))\n",
        "\n",
        "print(\"\\nRandom Forest Model:\")\n",
        "print(\"Accuracy: {:.2f}\".format(rf_accuracy))\n",
        "print(\"Precision: {:.2f}\".format(rf_precision))\n",
        "print(\"Recall: {:.2f}\".format(rf_recall))\n",
        "print(\"F1 Score: {:.2f}\".format(rf_f1))\n",
        "\n",
        "print(\"\\nNaive Bayes Model:\")\n",
        "print(\"Accuracy: {:.2f}\".format(nb_accuracy))\n",
        "print(\"Precision: {:.2f}\".format(nb_precision))\n",
        "print(\"Recall: {:.2f}\".format(nb_recall))\n",
        "print(\"F1 Score: {:.2f}\".format(nb_f1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLRm6m5zHd_e",
        "outputId": "a60d463b-406b-42a0-bab7-36ea69353f49"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Model:\n",
            "Accuracy: 0.84\n",
            "Precision: 0.86\n",
            "Recall: 0.94\n",
            "F1 Score: 0.83\n",
            "\n",
            "Random Forest Model:\n",
            "Accuracy: 0.85\n",
            "Precision: 0.86\n",
            "Recall: 0.96\n",
            "F1 Score: 0.84\n",
            "\n",
            "Naive Bayes Model:\n",
            "Accuracy: 0.78\n",
            "Precision: 0.80\n",
            "Recall: 0.95\n",
            "F1 Score: 0.74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "import matplotlib.pyplot as plt\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, NaiveBayes\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, NaiveBayes\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "\n",
        "\n",
        "# Step 1: Create a SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PySpark Classification\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Step 2: Load the data into a DataFrame\n",
        "data = spark.read.csv('/content/adult.csv', header=True, inferSchema=True)\n",
        "\n",
        "# Step 3: Drop rows with missing values in any of the selected columns\n",
        "selected_columns = ['age', 'workclass', 'fnlwgt', 'education', 'educational-num', 'marital-status',\n",
        "                    'occupation', 'relationship', 'race', 'gender', 'capital-gain', 'capital-loss',\n",
        "                    'hours-per-week', 'native-country', 'income']\n",
        "data = data.select(selected_columns).na.drop()\n",
        "\n",
        "# Step 4: Encode categorical columns with StringIndexer\n",
        "categorical_columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']\n",
        "for column in categorical_columns:\n",
        "    indexer = StringIndexer(inputCol=column, outputCol=column + \"_index\")\n",
        "    data = indexer.fit(data).transform(data)\n",
        "\n",
        "# Step 5: Convert the 'income' column to integer type (0 for '<=50K', 1 for '>50K')\n",
        "data = data.withColumn('label', (data['income'] == '>50K').cast('int'))\n",
        "\n",
        "# Step 6: Prepare the feature vector\n",
        "feature_columns = ['age', 'workclass_index', 'fnlwgt', 'education_index', 'educational-num', 'marital-status_index',\n",
        "                   'occupation_index', 'relationship_index', 'race_index', 'gender_index', 'capital-gain',\n",
        "                   'capital-loss', 'hours-per-week', 'native-country_index']\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "data = assembler.transform(data).select(\"features\", \"label\")\n",
        "\n",
        "# Step 7: Split the data into training and testing sets (70% training, 30% testing)\n",
        "train_data, test_data = data.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "# Step 8: Train the Logistic Regression model\n",
        "log_reg = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "log_reg_model = log_reg.fit(train_data)\n",
        "\n",
        "# Step 9: Evaluate the Logistic Regression model on the test data\n",
        "log_reg_predictions = log_reg_model.transform(test_data)\n",
        "log_reg_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
        "log_reg_accuracy = log_reg_evaluator.evaluate(log_reg_predictions)\n",
        "\n",
        "# Step 10: Train the Random Forest model with maxBins=50\n",
        "random_forest = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", maxBins=50)\n",
        "rf_model = random_forest.fit(train_data)\n",
        "\n",
        "# Step 11: Train the Naive Bayes model\n",
        "naive_bayes = NaiveBayes(featuresCol=\"features\", labelCol=\"label\")\n",
        "nb_model = naive_bayes.fit(train_data)\n",
        "\n",
        "# Step 12: Create a ParamGrid for Cross-Validation\n",
        "param_grid = ParamGridBuilder() \\\n",
        "    .addGrid(random_forest.maxDepth, [5, 10, 15]) \\\n",
        "    .addGrid(random_forest.numTrees, [10, 20, 30]) \\\n",
        "    .build()\n",
        "\n",
        "# Step 13: Create a CrossValidator with the Random Forest model\n",
        "crossval = CrossValidator(estimator=random_forest,\n",
        "                          estimatorParamMaps=param_grid,\n",
        "                          evaluator=MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\"),\n",
        "                          numFolds=3)\n",
        "\n",
        "# Step 14: Fit the CrossValidator to the training data\n",
        "cv_model = crossval.fit(train_data)\n",
        "\n",
        "# Step 15: Get the best Random Forest model from Cross-Validation\n",
        "best_rf_model = cv_model.bestModel\n",
        "\n",
        "# Step 16: Evaluate the best Random Forest model on the test data\n",
        "best_rf_predictions = best_rf_model.transform(test_data)\n",
        "\n",
        "# Step 17: Calculate and print the evaluation metrics for the best Random Forest model\n",
        "rf_accuracy_cv = evaluator.evaluate(best_rf_predictions, {evaluator.metricName: \"accuracy\"})\n",
        "rf_precision_cv = evaluator.evaluate(best_rf_predictions, {evaluator.metricName: \"precisionByLabel\"})\n",
        "rf_recall_cv = evaluator.evaluate(best_rf_predictions, {evaluator.metricName: \"recallByLabel\"})\n",
        "rf_f1_cv = evaluator.evaluate(best_rf_predictions, {evaluator.metricName: \"f1\"})\n",
        "\n",
        "# Step 18: Print the evaluation results for the best Random Forest model\n",
        "print(\"\\nBest Random Forest Model (with Cross-Validation):\")\n",
        "print(\"Accuracy: {:.2f}\".format(rf_accuracy_cv))\n",
        "print(\"Precision: {:.2f}\".format(rf_precision_cv))\n",
        "print(\"Recall: {:.2f}\".format(rf_recall_cv))\n",
        "print(\"F1 Score: {:.2f}\".format(rf_f1_cv))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsyfFKUIIDPF",
        "outputId": "bd2bdf78-71c3-4d72-beca-0920b78cae4b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Random Forest Model (with Cross-Validation):\n",
            "Accuracy: 0.86\n",
            "Precision: 0.89\n",
            "Recall: 0.94\n",
            "F1 Score: 0.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "import matplotlib.pyplot as plt\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, NaiveBayes\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, NaiveBayes\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "\n",
        "\n",
        "# Step 1: Create a SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PySpark Classification\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Step 2: Load the data into a DataFrame\n",
        "data = spark.read.csv('/content/adult.csv', header=True, inferSchema=True)\n",
        "\n",
        "# Step 3: Drop rows with missing values in any of the selected columns\n",
        "selected_columns = ['age', 'workclass', 'fnlwgt', 'education', 'educational-num', 'marital-status',\n",
        "                    'occupation', 'relationship', 'race', 'gender', 'capital-gain', 'capital-loss',\n",
        "                    'hours-per-week', 'native-country', 'income']\n",
        "data = data.select(selected_columns).na.drop()\n",
        "\n",
        "# Step 4: Encode categorical columns with StringIndexer\n",
        "categorical_columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']\n",
        "for column in categorical_columns:\n",
        "    indexer = StringIndexer(inputCol=column, outputCol=column + \"_index\")\n",
        "    data = indexer.fit(data).transform(data)\n",
        "\n",
        "# Step 5: Convert the 'income' column to integer type (0 for '<=50K', 1 for '>50K')\n",
        "data = data.withColumn('label', (data['income'] == '>50K').cast('int'))\n",
        "\n",
        "# Step 6: Prepare the feature vector\n",
        "feature_columns = ['age', 'workclass_index', 'fnlwgt', 'education_index', 'educational-num', 'marital-status_index',\n",
        "                   'occupation_index', 'relationship_index', 'race_index', 'gender_index', 'capital-gain',\n",
        "                   'capital-loss', 'hours-per-week', 'native-country_index']\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "data = assembler.transform(data).select(\"features\", \"label\")\n",
        "\n",
        "# Step 7: Split the data into training and testing sets (70% training, 30% testing)\n",
        "train_data, test_data = data.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "# Step 8: Train the Logistic Regression model\n",
        "log_reg = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "log_reg_model = log_reg.fit(train_data)\n",
        "\n",
        "# Step 9: Evaluate the Logistic Regression model on the test data\n",
        "log_reg_predictions = log_reg_model.transform(test_data)\n",
        "log_reg_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
        "log_reg_accuracy = log_reg_evaluator.evaluate(log_reg_predictions)\n",
        "\n",
        "# Step 10: Train the Random Forest model with maxBins=50\n",
        "random_forest = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", maxBins=50)\n",
        "rf_model = random_forest.fit(train_data)\n",
        "\n",
        "# Step 11: Train the Naive Bayes model\n",
        "naive_bayes = NaiveBayes(featuresCol=\"features\", labelCol=\"label\")\n",
        "nb_model = naive_bayes.fit(train_data)\n",
        "\n",
        "# Step 12: Set up the parameter grid for each model\n",
        "param_grid_lr = ParamGridBuilder() \\\n",
        "    .addGrid(log_reg.regParam, [0.01, 0.1, 0.5]) \\\n",
        "    .addGrid(log_reg.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
        "    .build()\n",
        "\n",
        "param_grid_rf = ParamGridBuilder() \\\n",
        "    .addGrid(random_forest.numTrees, [10, 20, 30]) \\\n",
        "    .addGrid(random_forest.maxDepth, [5, 10, 15]) \\\n",
        "    .build()\n",
        "\n",
        "param_grid_nb = ParamGridBuilder() \\\n",
        "    .addGrid(naive_bayes.smoothing, [0.1, 0.5, 1.0]) \\\n",
        "    .build()\n",
        "\n",
        "# Step 13: Set up the CrossValidator for each model\n",
        "crossval_lr = CrossValidator(estimator=log_reg,\n",
        "                             estimatorParamMaps=param_grid_lr,\n",
        "                             evaluator=evaluator,\n",
        "                             numFolds=3)\n",
        "\n",
        "crossval_rf = CrossValidator(estimator=random_forest,\n",
        "                             estimatorParamMaps=param_grid_rf,\n",
        "                             evaluator=evaluator,\n",
        "                             numFolds=3)\n",
        "\n",
        "crossval_nb = CrossValidator(estimator=naive_bayes,\n",
        "                             estimatorParamMaps=param_grid_nb,\n",
        "                             evaluator=evaluator,\n",
        "                             numFolds=3)\n",
        "\n",
        "# Step 14: Train the CrossValidator on the training data\n",
        "cv_model_lr = crossval_lr.fit(train_data)\n",
        "cv_model_rf = crossval_rf.fit(train_data)\n",
        "cv_model_nb = crossval_nb.fit(train_data)\n",
        "\n",
        "# Step 15: Make predictions using the best model on the test data\n",
        "lr_predictions = cv_model_lr.transform(test_data)\n",
        "rf_predictions = cv_model_rf.transform(test_data)\n",
        "nb_predictions = cv_model_nb.transform(test_data)\n",
        "\n",
        "# Step 16: Calculate and print evaluation metrics for the best models\n",
        "lr_accuracy = evaluator.evaluate(lr_predictions, {evaluator.metricName: \"accuracy\"})\n",
        "lr_precision = evaluator.evaluate(lr_predictions, {evaluator.metricName: \"precisionByLabel\"})\n",
        "lr_recall = evaluator.evaluate(lr_predictions, {evaluator.metricName: \"recallByLabel\"})\n",
        "lr_f1 = evaluator.evaluate(lr_predictions, {evaluator.metricName: \"f1\"})\n",
        "\n",
        "rf_accuracy = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"accuracy\"})\n",
        "rf_precision = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"precisionByLabel\"})\n",
        "rf_recall = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"recallByLabel\"})\n",
        "rf_f1 = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"f1\"})\n",
        "\n",
        "nb_accuracy = evaluator.evaluate(nb_predictions, {evaluator.metricName: \"accuracy\"})\n",
        "nb_precision = evaluator.evaluate(nb_predictions, {evaluator.metricName: \"precisionByLabel\"})\n",
        "nb_recall = evaluator.evaluate(nb_predictions, {evaluator.metricName: \"recallByLabel\"})\n",
        "nb_f1 = evaluator.evaluate(nb_predictions, {evaluator.metricName: \"f1\"})\n",
        "\n",
        "# Step 17: Print the evaluation results for all models\n",
        "print(\"Logistic Regression Model:\")\n",
        "print(\"Accuracy: {:.2f}\".format(lr_accuracy))\n",
        "print(\"Precision: {:.2f}\".format(lr_precision))\n",
        "print(\"Recall: {:.2f}\".format(lr_recall))\n",
        "print(\"F1 Score: {:.2f}\".format(lr_f1))\n",
        "\n",
        "print(\"\\nRandom Forest Model:\")\n",
        "print(\"Accuracy: {:.2f}\".format(rf_accuracy))\n",
        "print(\"Precision: {:.2f}\".format(rf_precision))\n",
        "print(\"Recall: {:.2f}\".format(rf_recall))\n",
        "print(\"F1 Score: {:.2f}\".format(rf_f1))\n",
        "\n",
        "print(\"\\nNaive Bayes Model:\")\n",
        "print(\"Accuracy: {:.2f}\".format(nb_accuracy))\n",
        "print(\"Precision: {:.2f}\".format(nb_precision))\n",
        "print(\"Recall: {:.2f}\".format(nb_recall))\n",
        "print(\"F1 Score: {:.2f}\".format(nb_f1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ibJzar_KWda",
        "outputId": "55d1be6a-cb5c-41a3-b59d-49e07d03a90e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Model:\n",
            "Accuracy: 0.83\n",
            "Precision: 0.85\n",
            "Recall: 0.95\n",
            "F1 Score: 0.82\n",
            "\n",
            "Random Forest Model:\n",
            "Accuracy: 0.86\n",
            "Precision: 0.89\n",
            "Recall: 0.94\n",
            "F1 Score: 0.86\n",
            "\n",
            "Naive Bayes Model:\n",
            "Accuracy: 0.78\n",
            "Precision: 0.80\n",
            "Recall: 0.95\n",
            "F1 Score: 0.74\n"
          ]
        }
      ]
    }
  ]
}